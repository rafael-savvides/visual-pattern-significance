---
title: "Significance of patterns in data visualisations"
author: Rafael Savvides
date: 2019-07-29
output: html_notebook
editor_options: 
  chunk_output_type: inline
---

```{r load_init}
rm(list=ls())
source("code/utilities.R")
source("code/functions.R")
source("code/pvalues.R")
source("code/plotting.R")
DIR_FIGURES <- "figures/"
randseed <- 42

check_if_packages_are_present(required_packages = c("scagnostics", "sp", "rmarkdown"))

library(scagnostics) # requires rJava which in turn requires Java Development Kit. 
library(sp)
```

This notebook replicates the experiments in the MSc thesis *Significance of patterns in data visualisations*. 
Every experiment can be run independently: in each section run the `load_*` chunk and then the remaining chunks.

# Tabular Data

```{r load_german}
german_orig <- readRDS("data/socio_economics_germany_full.rds")
german <- german_orig[, 14:45]
german <- scale(as.matrix(german))
german_factors <- german_orig[, 3:5]

set.seed(randseed)
split_ratio <- 0.5
idx_split <- sample(nrow(german), size = round(nrow(german) * split_ratio))

german_test <- german[-idx_split, ]
german_viz <- german[idx_split, ]

# Load parameters ------

# Scagnostics example
ind_vars_for_scag <- c(28, 7)
pvec_scag <- matrix(0, nrow = ncol(german), ncol = 2)
pvec_scag[ind_vars_for_scag[1], ] <- c(1, 0)
pvec_scag[ind_vars_for_scag[2], ] <- c(0, 1)

xy_scag <- matrix(german[, ind_vars_for_scag],
                  ncol = 2,
                  dimnames = list(NULL, colnames(german)[ind_vars_for_scag]))

# Iteration example (t=1) 
pvec_t1 <- matrix(ncol = 2,
                  byrow = T, 
                  data = c(-0.20812984,0.104020433,0.05990979, -0.099812793,-0.24639380, -0.117946512,-0.11624038,-0.287016907,0.27903707,0.130979455,-0.23985513, -0.101385960,0.05940001,-0.253213364,0.19738100,0.135532251,0.14333147,0.266455176,-0.06348592,-0.273316607,0.06425944,-0.161007169,-0.27982946, -0.026321798,0.23709035,-0.082338519,0.21782876,0.049192671,-0.08232096, -0.230579644,-0.10346176,-0.179110660,-0.21100813,-0.128821268,0.13862144, -0.058078100,0.04182044,-0.001105998,0.01557894, -0.256028765,-0.21179466,0.241864953,-0.06820454,0.235701968,-0.18061247,0.211785490,-0.20709077,0.142938684,0.01938115,0.282079429,0.18008659, -0.248325281,-0.01936813,-0.046666645,0.07365535,-0.286046537,0.22844881,-0.106202163,0.13828398,-0.045914802,0.29663816,0.030275195,0.29013785,0.042963275), 
                  dimnames = list(colnames(german_test), NULL))

xy_t1 <- german_viz %*% pvec_t1
R1_viz <- c(2,4,13,16,17,21,22,23,24,39,44,46,49,54,55,63,78,79,86,92,93,98,99,100,104,109,110,111,120,134,140,143,149,175,189,197,204) # KDD version with R 3.5.2.
R1_viz_chull_t1 <- convhull_subset(xy_t1, R1_viz)
R1_test <- points_in_selection(german_test %*% pvec_t1, R1_viz_chull_t1)

# Iteration example (t=2)
pvec_t2 <- matrix(ncol = 2, 
                  byrow = T, 
                  data = c(-0.182898728,0.046784628,0.086336015,-0.290675215,-0.097171720,0.089453203,0.146354042,0.196681478,0.237927378,0.090368043,-0.145360710,-0.089451254,0.211901628,0.086380488,0.065868274,-0.395870364,-0.185631925,-0.106229409,0.153883305,0.299982364,0.137294777,0.083407338,-0.281658636,-0.118886857,0.225993505,0.146757383,0.128587587,-0.308107602,0.101163722,0.187058399,0.044837537,0.120987483,-0.072485055,0.136796134,0.123300841,-0.145878983,0.024676426,-0.097395808,0.187339783,0.187941587,-0.266937912,-0.011652182,-0.184139352,-0.202973244,-0.239467629,0.049770157,-0.218674164,0.149115730,-0.209912778,-0.043875803,0.245354418,-0.048478112,0.004498666,-0.006959673,0.227218980,0.118740846,0.216991342,-0.200672373,0.119424376,-0.216416438,0.195314932,-0.347961240,0.207808410,-0.142741432),
                  dimnames = list(colnames(german_test), NULL))

xy_t2 <- german_viz %*% pvec_t2
xy_t2_in_R1 <- german_viz[R1_viz, ] %*% pvec_t2
R2_viz <-c(1,3,10,28,31,34,35,37,42,50,51,53,59,62,64,65,66,70,72,73,75,77,80,81,83,89,90,97,102,106,113,119,122,123,129,131,136,137,145,147,157,163,164,170,179,180,181,190,195,201,202,203,206)
R2_viz_chull_t2 <- convhull_subset(xy_t2, R2_viz)
R2_test <- points_in_selection(german_test %*% pvec_t2, R2_viz_chull_t2)

# Tiles are used for constrained randomization of the data. They enable sampling datasets with the same marginal distributions as the original data, or the same marginal distributions constrained by a pattern to enable iterative exploration.
# uc: unconstrained
tile_uc <- tiling(n = nrow(german_test), m = ncol(german_test))
tile_uc_full <- tiling(n = nrow(german), m = ncol(german))
```

## Scagnostics and permutations

We choose an axis-aligned projection of the data and compute its scagnostics.

We then run a statistical test with: 

* scagnostics as a test statistic
* independent column permutations as a null distribution

Since we have multiple test statistics (i.e. multiple hypotheses), the computed p-values are adjusted (with minP correction).

```{r fig_german_skewed, fig.asp=1, fig.width=2}
fig_german_skewed <- function(showSurrogates=F) {
  surrog <- NULL
  if (showSurrogates) {
    set.seed(42)
    surrog <- replicate(tile_uc_full$permutedata(german) %*% pvec_scag, 
                        n = 1000, 
                        simplify = F)
  }
  scatterplot_surrogates(xy_scag, surr=surrog[1:10], mar=c(1,0.5,0,0)+0.1)
  title(xlab = colnames(german)[ind_vars_for_scag][1],
        ylab = colnames(german)[ind_vars_for_scag][2], 
        line = 0, 
        cex.lab = 0.5)
}

fig_german_skewed(showSurrogates = T)
```

```{r}
set.seed(randseed)
test_german_scag <- tester(data = german, 
                           nresample = 1000, 
                           test_stat = scagnosticss, 
                           sample_from_null = function() tile_uc_full$permutedata(german), 
                           pvec = pvec_scag)

table_scag <- pvalue_table(test_points = names(test_german_scag$t0), 
                           include_t0 = T,
                           test=test_german_scag, 
                           name_points = "Scagnostic", 
                           name_t0 = "T")

print_xtable_formatted(t(as.matrix(table_scag)), 
                       include.rownames = FALSE, 
                       include.colnames = TRUE)
```

```{r pdf_german_skewed}
savePDF(fig_german_skewed(showSurrogates = T), paste0(DIR_FIGURES, "german-data-skewed.pdf"), width = 2, height = 2)
```

## Number of points in region and permutations

Instead of scagnostics, here we use as a test statistic the number of points inside a region. Furthermore, we demonstrate a multiple hypotheses correction for an iterative exploration scenario.

We consider two patterns found in the data:

* R1: Rural areas in the East region
* R2: Urban areas

```{r}
german_factors_test <- german_factors[-idx_split, ]
summary(german_factors_test[R1_test, ]) # Rural East
summary(german_factors_test[R2_test, ]) # Urban
```

### View 1

The German data are plotted to their first principal components. Now we observe a cluster $R_1$ and want to know whether it is significant or a random artifact of the data.

```{r fig_german_view1, fig.asp=1, fig.width=2}
fig_german_view1 <- function(showSurrogates=F, visualiseTestSet=F) {
  if (!visualiseTestSet) dat <- german_viz else dat <- german_test
  surrog <- NULL
  if (showSurrogates) {
    set.seed(42)
    tile_german_viz <- tiling(n = nrow(dat), m = ncol(dat))
    surrog <- replicate(tile_german_viz$permutedata(dat) %*% pvec_t1, 
                        n = 1000, 
                        simplify = F)
  }
  scatterplot_surrogates(dat %*% pvec_t1, surr=surrog[1:10])
  plot_polygon(R1_viz_chull_t1)
}

fig_german_view1(showSurrogates=T)
```

```{r pdf_german_view1}
savePDF(fig_german_view1(showSurrogates = T), paste0(DIR_FIGURES, "german-data-view1.pdf"), width = 2, height = 2)
savePDF(fig_german_view1(), paste0(DIR_FIGURES, "german-data-view1a.pdf"), width = 2, height = 2)
savePDF(fig_german_view1(showSurrogates = T, visualiseTestSet = T), paste0(DIR_FIGURES, "german-data-view1b.pdf"), width = 2, height = 2)
```

The x and y axes in this view have the following combination of variables (5 largest absolute weights): 

```{r}
i_t1 <- head(order(abs(pvec_t1[, 1]), decreasing = T), 5)
j_t1 <- head(order(abs(pvec_t1[, 2]), decreasing = T), 5)
data.frame(
  x = rownames(pvec_t1)[i_t1],
  w_x = round(pvec_t1[i_t1, 1], 2),
  y = rownames(pvec_t1)[j_t1],
  w_y = round(pvec_t1[j_t1, 2], 2)
)
```

We use as a test statistic the number of points inside the marked region and as a null distribution (again) independent column permutations.  

The observed pattern has an iteration-adjusted p-value of:

```{r}
set.seed(randseed)

test_R1_t1_uc <- tester(german_test, 
                        nresample = 1000, 
                        test_stat = num_points_in_selection, 
                        sample_from_null = function() tile_uc$permutedata(german_test), 
                        pvec = pvec_t1, 
                        region = R1_viz_chull_t1)

pval_iter_adj(pvalue(test_R1_t1_uc), t = 1)
```

When we constrain the null distribution by the selected points, the pattern is no longer significant, hence it has a p-value:

```{r}
set.seed(randseed)

tile_R1 <- tile_uc$copy()
tile_R1$addtile(R = R1_test)

test_R1_t1_cR1 <- tester(german_test, 
                         nresample = 1000, 
                         test_stat = num_points_in_selection, 
                         sample_from_null = function() tile_R1$permutedata(german_test), 
                         pvec = pvec_t1, 
                         region = R1_viz_chull_t1)

pval_iter_adj(pvalue(test_R1_t1_cR1), t = 1)
```

### View 2
A new view is obtained by adding the previously observed pattern to the *background distribution*. The previously observed pattern $R_1$ is marked with red crosses. 

Suppose we observe a new pattern $R_2$ (marked with a polygon) and want to know whether it is significant. 

* The test statistic in this case is again the number of points inside the region.
* The null distribution is the same as in the previous step, with an added constraint on the first observed pattern $R_1$.
* Because this is the second iteration step, we apply the iteration correction for multiple hypotheses.

```{r fig_german_view2, fig.asp=1, fig.width=2}
fig_german_view2 <- function(showSurrogates=F) {
  surrog <- NULL
  if (showSurrogates) {
    set.seed(42)
    tile_german_viz <- tiling(n = nrow(german_viz), m = ncol(german_viz))
    surrog <- replicate(tile_german_viz$permutedata(german_viz) %*% pvec_t2, 
                        n = 1000, 
                        simplify = F)
  }
  scatterplot_surrogates(xy_t2, surr=surrog[1:10])
  points(xy_t2_in_R1, col = rgb(0.8, 0, 0, 0.5), pch = 4, cex = 0.4)
  plot_polygon(R2_viz_chull_t2)  
}

fig_german_view2(showSurrogates = T)
```

The x and y axes in this view have the following combination of variables (5 largest absolute weights): 

```{r}
i_t2 <- head(order(abs(pvec_t2[, 1]), decreasing = T), 5)
j_t2 <- head(order(abs(pvec_t2[, 2]), decreasing = T), 5)
data.frame(
  x = rownames(pvec_t2)[i_t2],
  w_x = round(pvec_t2[i_t2, 1], 2),
  y = rownames(pvec_t2)[j_t2],
  w_y = round(pvec_t2[j_t2, 2], 2)
)
```

```{r pdf_german_view2}
savePDF(fig_german_view2(showSurrogates = T), paste0(DIR_FIGURES, "german-data-view2.pdf"), width = 2, height = 2)
```

We hence get an iteration-adjusted p-value of:

```{r}
set.seed(randseed)
test_R2_t2_cR1 <- tester(german_test, 
                         nresample = 1000, 
                         test_stat = num_points_in_selection, 
                         sample_from_null = function() tile_R1$permutedata(german_test), 
                         pvec = pvec_t2, 
                         region = R2_viz_chull_t2)
pval_iter_adj(pvalue(test_R2_t2_cR1), t=2)
```

# Time Series

## Peak value and Gaussian processes

```{r load_ts_gp, fig.width=4, fig.height=2}
AQ <- readAQ()
AQ_time <- AQ$time
AQ_CO <- scale(AQ$CO.GT.)[,1]

ind_day1 <- 343:366
x_day1 <- AQ_time[ind_day1]
y_day1 <- AQ_CO[ind_day1]
x_test <- seq(from = x_day1[1],
              to = x_day1[length(x_day1)],
              length.out = length(x_day1))
x_train <- x_day1[c(20)]
y_train <- y_day1[c(20)]
length_scale <- 3600*6

set.seed(randseed)
gp1 <- GP(x_test, x_train, y_train, kern = function(x, y) kernel_sqexp(x, y, l = length_scale))
surrogates_gp_prior <- gp1$prior(25)
surrogates_gp_post <- gp1$post(25)
sample_from_gp_prior <- function() gp1$prior(1)[,1]
sample_from_gp_post <- function() gp1$post(1)[,1]
```

```{r fig_ts_gp}
fig_ts_prior <- function() plot_ts(x_day1, y_day1, 
                                   x_test, surrogates_gp_prior, 
                                   ylim = range(c(y_day1, surrogates_gp_post, surrogates_gp_prior)), 
                                   mar = c(2, 1, 0, 1) + 0.1)
fig_ts_post <- function() plot_ts(x_day1, y_day1, 
                                  x_test, surrogates_gp_post, 
                                  ylim = range(c(y_day1, surrogates_gp_post, surrogates_gp_prior)), 
                                  mar = c(2, 1, 0, 1) + 0.1)

fig_ts_prior()
fig_ts_post()
```

```{r pdf_ts_gp, message=FALSE}
savePDF(fig_ts_prior(), paste0(DIR_FIGURES, "ts-prior.pdf"), width = 8, height = 4)
savePDF(fig_ts_post(), paste0(DIR_FIGURES, "ts-post.pdf"), width = 8, height = 4)
```

We run a statistical test: 

* test statistics are the values of the time series at every point (multiple test statistics = multiple hypotheses). 
* the null distribution is a Gaussian process with a length scale of 6 hours (two GPs are considered: one unconstrained and one constrained). 
* we use minP as a multiple hypotheses correction.

We also run the test after adding a constraint on the highest point to demonstrate that it is no longer significant. 

```{r}
set.seed(randseed)
value_at_every_time_instance <- function(x) x 
# uc: Unconstrained
test_ts_uc <- tester(y_day1, 
                     nresample = 1000, 
                     test_stat = value_at_every_time_instance, 
                     sample_from_null = sample_from_gp_prior)
# c: Constrained
test_ts_c <- tester(y_day1, 
                    nresample = 1000, 
                    test_stat = function(x) x, 
                    sample_from_null = sample_from_gp_post)
```

The highest point at 19:00 is indeed significant (pval_prior = 0.1). 

When we add a constraint on it, it is no longer significant (pval_post = 0.99). 

```{r}
set.seed(randseed)

test_ts_uc_pvadj <- minP(test_ts_uc$t0, t(test_ts_uc$t))
test_ts_c_pvadj <- minP(test_ts_c$t0, t(test_ts_c$t))

data.frame(time = as.POSIXlt(x_test, origin="1970-01-01"), 
           pval_prior = round(test_ts_uc_pvadj, 2), 
           pval_post = round(test_ts_c_pvadj, 2))

test_points_ts1 <- format(as.POSIXlt(x_test, origin="1970-01-01"), "%H")
table_ts1 <- pvalue_table(test_points=test_points_ts1, 
                          test=test_ts_uc, 
                          name_points="time")

print_xtable_formatted(table_ts1[1:12, ])
print_xtable_formatted(table_ts1[13:24, ])
```


## Difference in interval and historical surrogates

Here we demonstrate: 

* a null model for time series based on sampling from historical surrogates.
* a test statistic based on the difference in an interval [a,b].

```{r load_ts_history, fig.width=4, fig.height=2}
AQ <- readAQ()
AQ_time <- AQ$time
AQ_CO <- scale(AQ$CO.GT.)[,1]
ind_day2 <- 151:174
x_day2 <- AQ_time[ind_day2]
y_day2 <- AQ_CO[ind_day2]
a <- 8 # 7am
b <- 10 # 9am

set.seed(randseed)
AQ_workdays <- as.POSIXlt(AQ_time, origin="1970-01-01")$wday %in% 1:5
sample_workday_AQ <- function() {
  unlist(make_sample_full_days(
    make_sample_days(
      data.frame(
        time=as.POSIXct(AQ_time, origin="1970-01-01"), 
        `CO.GT.` = AQ_CO
      )[AQ_workdays, ]
    ), 
    day_length = 24)()["CO.GT."]) 
}

surrogates_historical <- replicate(n=25, sample_workday_AQ(), simplify = T)
```

```{r fig_ts_history}
fig_ts_history <- function() {
  plot_ts(x_day2, y_day2, 
          x_day2, surrogates_historical, 
          mar=c(2, 1, 0, 1) + 0.1)
  abline(v = x_day2[c(a,b)], lty = 2, col = "blue", lwd = 2)
}

fig_ts_history()
```

```{r pdf_ts_history}
savePDF(fig_ts_history(), paste0(DIR_FIGURES, "ts-history.pdf"), width = 8, height = 4)
```

A naive testing procedure, using as a test statistic the difference between $a$ and $b$ for the marked interval gives a p-value of: 

```{r warning=FALSE}
set.seed(randseed)
diff_in_interval <- function(data, t1 = a, t2 = b) data[t2] - data[t1] 
test_ts_diff_naive <- tester(y_day2, 
                       nresample = 1000, 
                       test_stat = diff_in_interval, 
                       sample_from_null = sample_workday_AQ)
pvalue(test_ts_diff_naive)
```

If we instead use as a test statistic all possible intervals of length 2 then for the interval in question we get a minP-adjusted p-value of: 

```{r }
set.seed(randseed)
diff_in_intervals_length_L <- function(x) apply_to_intervals(as.matrix(x),
                                                             f = diff_in_interval,
                                                             L = 2,
                                                             returnNamed = T)
test_ts_diff_every_interval <- tester(y_day2, 
                        nresample = 1000, 
                        test_stat = diff_in_intervals_length_L, 
                        sample_from_null = sample_workday_AQ)
```

```{r}
x_day2_pretty <- format(as.POSIXlt(x_day2, origin="1970-01-01"), "%H")
test_points_ts_history <- apply_to_intervals(as.matrix(x_day2_pretty), 
                                             f=function(x, a, b) paste(x[a], x[b],
                                                                       sep="-"), 
                                             L=2)
# NAs are replaced with -Inf. The assumption is that an NA is insignificant.
table_ts_history <- pvalue_table(test_points = test_points_ts_history, 
                                 test=test_ts_diff_every_interval, 
                                 name_points = "interval")
print_xtable_formatted(table_ts_history[1:11, ])
print_xtable_formatted(table_ts_history[12:22, ])
```

## Banana plot

```{r load_banana}
smear_data <- readRDS("data/smear_2010.rds") 
smear_events <- readRDS("data/smear_2010_events.rds") # This dataset is not public. Contact me if you need it.

sample_days <- make_sample_days(smear_data)
sample_full_nev_days_as_matrix <- make_sample_full_days(make_sample_days(smear_data[smear_events %in% c("non.event"),], returnMatrixWithoutTimestamp = T), 
                                                        day_length = 144) # Null distribution
quantile25 <- function(x) quantile(x, 0.25, na.rm=T, names=F) # Test statistic

user_line <- list(x0=93, y0=22, x1=132, y1=28)
smear_20100702 <- sample_days(d="2010-07-02")[, -2] # Remove NA column.
smear_20100702_test_params <- make_banana_test_param(day=smear_20100702, 
                                                     n_lines = 1000, 
                                                     type = "rising", 
                                                     user_line = user_line)
```

```{r fig_banana}
fig_banana <- function() {banana_plot_lines_wrapper(smear_20100702_test_params, idx_lines2test=F, grid=NULL)}
fig_banana()

set.seed(51)
test_banana <- tester(data = as.matrix(smear_20100702_test_params$data[-1]), 
                      sample_from_null = sample_full_nev_days_as_matrix, 
                      nresample = 1000, 
                      test_stat = compute_f_on_lines2test,
                      lines2test = smear_20100702_test_params$lines2test, 
                      f=quantile25
                      )

fig_banana_grid_lines <- function() {banana_plot_lines_wrapper(smear_20100702_test_params, idx_lines2test=T, idx_signif_lines = pvalue_minP(test_banana) <= 0.1)}
fig_banana_grid_lines()
```

```{r}
table_banana <- pvalue_table(test_points = test_banana$t0, 
                             test=test_banana, 
                             name_points = "$q_{25}$")
table_banana <- table_banana[order(table_banana$`$p_{minP}$`), ]
table_banana[1] <- df2matrix_plus1_log(table_banana[1])
rownames(table_banana) <- gsub("R", "\\\\#", rownames(table_banana))
print_xtable_formatted(table_banana[1:13, ], caption="", label="tab:banana", include.colnames = T)
```

```{r pdf_banana}
savePDF(fig_banana(), paste0(DIR_FIGURES, "banana.pdf"), width = 8, height = 4)
savePDF(fig_banana_grid_lines(), paste0(DIR_FIGURES, "banana-grid-lines.pdf"), width = 8, height = 4)
```

# Simulated user experiment

```{r}
# Takes ~5-10min
set.seed(randseed)
n_rep <- 1000
user_exp_params <- list(
  K=seq(from=0, to=1, length=100),
  N=c(1, 10, 25, 50, 100, 250, 500, 1000),
  nresample=250,
  mu=3,
  beta=0.5
)
set.seed(randseed)
user_experiment <- replicate(n=n_rep, do.call(function(...) do_user_experiment(...)$res, user_exp_params))
user_experiment_mean <- matrix(0, nrow = dim(user_experiment)[1], ncol = dim(user_experiment)[2])
for (i in 1:dim(user_experiment)[1]) for (j in 1:dim(user_experiment)[2]) user_experiment_mean[i, j] <- mean(user_experiment[i, j, ])
```

We observe that:

* For high $k$ (expertise), the user finds the significant pattern (low p-value) even with increasing number of test statistics $n$.
* For low $n$ (number of test statistics), even the non-expert user (low $k$) can find the significant pattern by chance alone.

```{r fig_user_exp, fig.width=10, fig.height=4}
color_function <- colorRampPalette(c("white", "darkblue"))

fig_user_exp <- function() {
  K <- user_exp_params$K
  N <- user_exp_params$N
  par(mar = c(4, 4, 1, 1) + 0.1,
      cex.axis = 1.2,
      cex.lab = 1.2)
  filled.contour(
    x = K,
    y = log(N),
    z = user_experiment_mean,
    plot.axes = {
      axis(1, at = pretty(K), label = pretty(K))
      axis(2, at = log(N), label = N)
    },
    color = color_function,
    xlab = "k",
    ylab = "n"
  )
}
fig_user_exp()
```

```{r pdf_user_exp}
savePDF(fig_user_exp(), paste0(DIR_FIGURES, "user-model-experiments.pdf"), width = 10, height = 4)
```